{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7992b9-a037-4142-b41e-7a5b3f565374",
   "metadata": {},
   "source": [
    "# Data Scraping #\n",
    "\n",
    "The first step is getting data. Fotunately, [NOAA](https://www.noaa.gov/) had provided many climate dataset.\n",
    "\n",
    "In this totorial, we will use the dataset from [Global Forecast System (GFS)](https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs) \n",
    "\n",
    "And scrape the `GRIB data(.grb)` and `GRIB2 data(.grb2)` from `Product Types` > `GFS Analysis` > `GFS-ANL, Historical Model` which is this [link](https://www.ncei.noaa.gov/data/global-forecast-system/access/historical/analysis/)\n",
    "\n",
    "The `period of record` of this dataset is `01Jan2007â€“15May2020` and the data was collected `4 times per day` `(00, 06, 12 and 18 UTC)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8bcb5-a6db-44ae-8eb5-e34c35ea8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68345a9-2712-4d0a-b3a4-2c116100f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = 'https://www.ncei.noaa.gov/data/global-forecast-system/access/historical/analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3501ca-1bac-4e63-86a2-a497053dde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(\"2007-01-01\",\"2020-05-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd93f14-9717-4b58-8b1c-1f2854a8c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_if_not_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e593ca-f084-4e72-81f1-2214e77af2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data/'\n",
    "create_dir_if_not_exist(root_dir)\n",
    "\n",
    "for date in tqdm(dates):\n",
    "    try:\n",
    "        year_month = date.strftime(\"%Y%m\")\n",
    "        year_month_day = date.strftime(\"%Y%m%d\")\n",
    "        dir = root_dir + year_month + '/' + year_month_day + '/'\n",
    "        create_dir_if_not_exist(dir)\n",
    "        url = url_template + year_month + '/' + year_month_day + '/'\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "        file_links = []\n",
    "        file_links = soup.findAll('a', href=lambda link: '000.grb2' in link and 'gfsanl_4' in link)\n",
    "        if len(file_links) == 0:\n",
    "            threes = soup.findAll('a', href=lambda link: '000.grb' in link and 'gfsanl_3' in link)\n",
    "            if len(threes) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                file_links = threes\n",
    "                \n",
    "        for link in file_links:\n",
    "            file_url = url + link['href']\n",
    "            urllib.request.urlretrieve(file_url, dir + link['href'])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2fb98-16f2-429e-8bf3-89d82b3d1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r data.zip data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f4e99-5547-4bad-9429-ff59a0805013",
   "metadata": {},
   "source": [
    "At this point, we can get the climate dataset. Unfortunately, we still doesn't know which data are there in the dataset. \n",
    "\n",
    "So, the next section in this tutorial is **Data Inspecting**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
